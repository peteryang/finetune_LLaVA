{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOX96jCseDcaLTT7/CgKNoP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peteryang/finetune_LLaVA/blob/main/llava_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRnb_rmgxc63",
        "outputId": "b7caeccd-c018-481e-feb4-a0bea6a49377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ],
      "source": [
        "!conda --version\n",
        "#If !conda --version returns no results, install conda with :\n",
        "!pip install -q condacolab\n",
        "#import condacolab\n",
        "#condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOt2ySm8xpcP",
        "outputId": "9a2c41ea-f39e-4ddf-fe71-44bdd35bc331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:12\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -y -q -n llava python=3.10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNkzIOcezHb_",
        "outputId": "570198c9-13ac-451e-f0ea-fc60ea39c30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/llava\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2024.2.2   |       hbcca054_0         152 KB  conda-forge\n",
            "    ld_impl_linux-64-2.40      |       h55db66e_0         697 KB  conda-forge\n",
            "    libgcc-ng-13.2.0           |       h77fa898_7         758 KB  conda-forge\n",
            "    libgomp-13.2.0             |       h77fa898_7         412 KB  conda-forge\n",
            "    libsqlite-3.45.3           |       h2797004_0         840 KB  conda-forge\n",
            "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
            "    ncurses-6.5                |       h59595ed_0         867 KB  conda-forge\n",
            "    openssl-3.3.0              |       hd590300_0         2.8 MB  conda-forge\n",
            "    pip-24.0                   |     pyhd8ed1ab_0         1.3 MB  conda-forge\n",
            "    python-3.10.14             |hd12c33a_0_cpython        24.3 MB  conda-forge\n",
            "    setuptools-69.5.1          |     pyhd8ed1ab_0         490 KB  conda-forge\n",
            "    tzdata-2024a               |       h0c530f3_0         117 KB  conda-forge\n",
            "    wheel-0.43.0               |     pyhd8ed1ab_1          57 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        32.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hd590300_5 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.2.2-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h55db66e_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-13.2.0-h77fa898_7 \n",
            "  libgomp            conda-forge/linux-64::libgomp-13.2.0-h77fa898_7 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.45.3-h2797004_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-hd590300_5 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h59595ed_0 \n",
            "  openssl            conda-forge/linux-64::openssl-3.3.0-hd590300_0 \n",
            "  pip                conda-forge/noarch::pip-24.0-pyhd8ed1ab_0 \n",
            "  python             conda-forge/linux-64::python-3.10.14-hd12c33a_0_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-69.5.1-pyhd8ed1ab_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2024a-h0c530f3_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.43.0-pyhd8ed1ab_1 \n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init"
      ],
      "metadata": {
        "id": "fzXAzVsCznTQ",
        "outputId": "d07aba02-3457-491f-b194-fda79a570cf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.10/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate llava"
      ],
      "metadata": {
        "id": "ZfDs9eN-zwg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -y -c nvidia cuda-compiler"
      ],
      "metadata": {
        "id": "Fe49X3wQ0uID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda list |grep nvidia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHCTFBtn1Yxr",
        "outputId": "26ce25cf-deeb-4b49-9d08-af6a491ad547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda-compiler             12.4.1                        0    nvidia\n",
            "cuda-cuobjdump            12.4.127                      0    nvidia\n",
            "cuda-cuxxfilt             12.4.127                      0    nvidia\n",
            "cuda-nvcc                 12.4.131                      0    nvidia\n",
            "cuda-nvprune              12.4.127                      0    nvidia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pre-commit==3.0.2\n",
        "\n",
        "# Install package locally\n",
        "!pip install --upgrade pip  # enable PEP 660 support\n",
        "!cd finetune_LLaVA/\n",
        "!pip install -e /content/finetune_LLaVA\n",
        "\n",
        "# Install additional packages for training\n",
        "!pip install -e \"/content/finetune_LLaVA[train]\"\n",
        "!pip install flash-attn --no-build-isolation\n"
      ],
      "metadata": {
        "id": "uFwqJDyy2Mgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/liuhaotian/llava-v1.5-7b /content/llava-v1.5-7b"
      ],
      "metadata": {
        "id": "gTtot_O6dcFY",
        "outputId": "511bb23d-b333-4d9c-84a4-f1eaa9d8284c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/llava-v1.5-7b'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 22 (delta 2), reused 1 (delta 1), pack-reused 16 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (22/22), 6.82 KiB | 1.14 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "kfb63uR-eG39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import uuid\n",
        "\n",
        "\n",
        "def process_and_save(dataset, output_folder, subset_name):\n",
        "    # Define image subfolder within output folder\n",
        "    subset_folder = os.path.join(output_folder, subset_name)\n",
        "    image_subfolder = os.path.join(output_folder, 'images')\n",
        "\n",
        "\n",
        "    if not os.path.exists(image_subfolder):\n",
        "        os.makedirs(image_subfolder)\n",
        "\n",
        "\n",
        "    if not os.path.exists(subset_folder):\n",
        "        os.makedirs(subset_folder)\n",
        "\n",
        "\n",
        "    # Initialize list to hold all JSON data\n",
        "    json_data_list = []\n",
        "\n",
        "\n",
        "    # Process and save images and labels\n",
        "    for item in dataset:\n",
        "        # Load image if it's a URL or a file path\n",
        "        if isinstance(item['image'], str):\n",
        "            response = requests.get(item['image'])\n",
        "            image = Image.open(BytesIO(response.content))\n",
        "        else:\n",
        "            image = item['image']  # Assuming it's a PIL.Image object\n",
        "\n",
        "\n",
        "        # Create a unique ID for each image\n",
        "        unique_id = str(uuid.uuid4())\n",
        "\n",
        "\n",
        "        # Define image path\n",
        "        image_path = os.path.join(image_subfolder, f\"{unique_id}.jpg\")\n",
        "\n",
        "\n",
        "        # Save image\n",
        "        image.save(image_path)\n",
        "\n",
        "\n",
        "        # Remove duplicates and format answers\n",
        "        answers = item['answers']\n",
        "        unique_answers = list(set(answers))\n",
        "        formatted_answers = \", \".join(unique_answers)\n",
        "\n",
        "\n",
        "        # Structure for LLaVA JSON\n",
        "        json_data = {\n",
        "            \"id\": unique_id,\n",
        "            \"image\": f\"{unique_id}.jpg\",\n",
        "            \"conversations\": [\n",
        "                {\n",
        "                    \"from\": \"human\",\n",
        "                    \"value\": item['question']\n",
        "                },\n",
        "                {\n",
        "                    \"from\": \"gpt\",\n",
        "                    \"value\": formatted_answers\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "\n",
        "        # Append to list\n",
        "        json_data_list.append(json_data)\n",
        "\n",
        "\n",
        "    # Save the JSON data list to a file\n",
        "    json_output_path = os.path.join(output_folder, subset_name, 'dataset.json')\n",
        "    with open(json_output_path, 'w') as json_file:\n",
        "        json.dump(json_data_list, json_file, indent=4)\n",
        "\n",
        "\n",
        "def save_dataset(dataset_name, output_folder, class_name, subset_name, val_samples=None):\n",
        "    # Load the dataset from Hugging Face\n",
        "    dataset = load_dataset(dataset_name, split=subset_name)\n",
        "\n",
        "\n",
        "    # Filter for images with the specified class in 'question_type'\n",
        "    filtered_dataset = [item for item in dataset if item['question_type'] == class_name]\n",
        "\n",
        "\n",
        "    # Determine the split for training and validation\n",
        "    if val_samples is not None and subset_name == 'train':\n",
        "        train_dataset = filtered_dataset[val_samples:]\n",
        "        val_dataset = filtered_dataset[:val_samples]\n",
        "    else:\n",
        "        train_dataset = filtered_dataset\n",
        "        val_dataset = []\n",
        "\n",
        "\n",
        "    # Process and save the datasets\n",
        "    for subset, data in [('train', train_dataset), ('validation', val_dataset)]:\n",
        "        if data:\n",
        "            process_and_save(data, output_folder, subset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Usage example\n",
        "output_folder = 'dataset'\n",
        "class_name = 'other'\n",
        "val_samples = 300\n",
        "save_dataset('Multimodal-Fatima/OK-VQA_train', output_folder, class_name, 'train', val_samples)\n",
        "save_dataset('Multimodal-Fatima/OK-VQA_test', output_folder, class_name, 'test')"
      ],
      "metadata": {
        "id": "4oWMilvpeJrV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}